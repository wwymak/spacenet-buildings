{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas \n",
    "\n",
    "#### replicate /use the discriminative loss func for instance segmentation\n",
    "\n",
    "- [Semantic Instance Segmentation with a Discriminative Loss Function](https://arxiv.org/abs/1708.02551)\n",
    "- useful github repo here https://github.com/Wizaron/instance-segmentation-pytorch\n",
    "\n",
    "#### deep watershed transform \n",
    "- https://spark-in.me/post/playing-with-dwt-and-ds-bowl-2018\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.imports import *\n",
    "from fastai.vision import *\n",
    "import tifffile as tiff\n",
    "from skimage.external import tifffile as sktif\n",
    "from joblib import Parallel, delayed\n",
    "import torch.functional as F\n",
    "\n",
    "from torch.nn.modules.loss import _Loss\n",
    "from torch.autograd import Variable\n",
    "import torch\n",
    "\n",
    "import functools, traceback\n",
    "def gpu_mem_restore(func):\n",
    "    \"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            type, val, tb = sys.exc_info()\n",
    "            traceback.clear_frames(tb)\n",
    "            raise type(val).with_traceback(tb) from None\n",
    "    return wrapper\n",
    "\n",
    "os.environ['FASTAI_TB_CLEAR_FRAMES']=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/media/wwymak/Storage/urban-3D-satellite\")\n",
    "train_dir = data_dir / \"training\"\n",
    "cropped_dir =  data_dir / \"cropped_training\"\n",
    "cropped_val_dir =  data_dir / \"cropped_validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_id(fname):\n",
    "    fname = fname.replace('_RGB.tif', '')\n",
    "    img_id = \"_\".join(fname.split('_')[:-1])\n",
    "    return img_id\n",
    "\n",
    "train_img_ids = [get_img_id(f.name) for f in cropped_dir.ls() if f.name.endswith('RGB.tif')]\n",
    "val_img_ids = [get_img_id(f.name) for f in cropped_val_dir.ls() if f.name.endswith('RGB.tif')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding_mean(prediction, taget):\n",
    "    \"\"\"\n",
    "    target shape=batch_size x w x \n",
    "    \"\"\"\n",
    "    n_instances = target.size(2)\n",
    "    pass\n",
    "\n",
    "def variance_term(prediction, target):\n",
    "    pass\n",
    "\n",
    "def distance_term():\n",
    "    pass\n",
    "\n",
    "def regularisation_term():\n",
    "    pass\n",
    "\n",
    "def discriminative_loss():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Tensor([[2,3],[1,3], [2,4]\n",
    "])\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet_l"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (solaris)",
   "language": "python",
   "name": "solaris"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
