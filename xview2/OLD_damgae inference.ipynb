{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: PROJ_LIB=/home/wwymak/anaconda3/envs/solaris/share/proj\n",
      "WARNING:tensorflow:From /home/wwymak/anaconda3/envs/fastai-solaris/lib/python3.7/site-packages/solaris/nets/metrics.py:103: The name tf.keras.metrics.cosine_proximity is deprecated. Please use tf.keras.losses.cosine_similarity instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/wwymak/anaconda3/envs/fastai-solaris/lib/python3.7/site-packages/solaris/nets/_keras_losses.py:104: The name tf.keras.losses.cosine is deprecated. Please use tf.keras.losses.cosine_similarity instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from shapely import wkt\n",
    "from shapely.geometry import Polygon\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env PROJ_LIB=/home/wwymak/anaconda3/envs/solaris/share/proj\n",
    "%matplotlib inline\n",
    "\n",
    "import rasterio\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import skimage\n",
    "import geopandas as gpd\n",
    "from matplotlib import pyplot as plt\n",
    "from shapely.ops import cascaded_union\n",
    "import solaris as sol\n",
    "\n",
    "from tqdm import tqdm\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from functools import partial\n",
    "\n",
    "from fastai.imports import *\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import dice\n",
    "from fastai.callbacks import *\n",
    "import ujson as json\n",
    "from joblib import Parallel, delayed\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import functools, traceback\n",
    "def gpu_mem_restore(func):\n",
    "    \"\"\"Reclaim GPU RAM if CUDA out of memory happened, or execution was interrupted\"\"\"\n",
    "    @functools.wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        try:\n",
    "            return func(*args, **kwargs)\n",
    "        except:\n",
    "            type, val, tb = sys.exc_info()\n",
    "            traceback.clear_frames(tb)\n",
    "            raise type(val).with_traceback(tb) from None\n",
    "    return wrapper\n",
    "\n",
    "os.environ['FASTAI_TB_CLEAR_FRAMES']=\"1\"\n",
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path(\"/media/wwymak/Storage/xView2\")\n",
    "mask_dir = data_dir /\"mask_full_size\"\n",
    "\n",
    "train_images_crops = data_dir/\"train_crops\"\n",
    "# train_mask_crops = data_dir/\"mask_crops\"\n",
    "train_mask_crops = data_dir/\"mask_crops_single_channel\"\n",
    "test_images_crops = data_dir / \"test_crops\"\n",
    "test_mask_crops = data_dir / \"test_mask_crops_single_channel\"\n",
    "test_masks_edt = data_dir / \"test_masks_edt\"\n",
    "classifcation_crop_dir = data_dir/\"classification_crops_post\"\n",
    "\n",
    "data_dir = Path(\"/media/wwymak/Storage/xView2\")\n",
    "mask_dir = data_dir /\"mask_full_size\"\n",
    "models_path = data_dir / \"models\"\n",
    "train_images_crops = data_dir/\"train_crops\"\n",
    "mask_dir_edt = data_dir /\"mask_full_size_edt\"\n",
    "train_mask_crops = data_dir/\"mask_crops_single_channel\"\n",
    "label_dir = data_dir/\"train\"/\"labels\"\n",
    "mask_crops_edt = data_dir/\"mask_crops_edt\"\n",
    "test_crops = data_dir/\"test_crops\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>value</th>\n",
       "      <th>polygon_id</th>\n",
       "      <th>img_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>POLYGON ((612 10, 612 12, 608 12, 608 16, 606 ...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>b44cd049-e8f6-4af9-84d6-c1327af8b46d</td>\n",
       "      <td>test_localization_00000_prediction.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>POLYGON ((736 0, 736 2, 738 2, 738 4, 742 4, 7...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0fa46888-a175-4802-ad94-93425524dc71</td>\n",
       "      <td>test_localization_00000_prediction.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>POLYGON ((572 44, 572 48, 570 48, 570 50, 568 ...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>9807c798-dcc7-4afc-859d-c55c5d5873ef</td>\n",
       "      <td>test_localization_00000_prediction.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>POLYGON ((556 76, 556 78, 552 78, 552 82, 550 ...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>ceb99454-2f1c-48a5-ae5f-d5e64020711e</td>\n",
       "      <td>test_localization_00000_prediction.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>POLYGON ((734 38, 734 40, 732 40, 732 42, 728 ...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>298c5b42-88d1-4b86-bbba-822939099be8</td>\n",
       "      <td>test_localization_00000_prediction.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry  value  \\\n",
       "0  POLYGON ((612 10, 612 12, 608 12, 608 16, 606 ...  255.0   \n",
       "1  POLYGON ((736 0, 736 2, 738 2, 738 4, 742 4, 7...  255.0   \n",
       "2  POLYGON ((572 44, 572 48, 570 48, 570 50, 568 ...  255.0   \n",
       "3  POLYGON ((556 76, 556 78, 552 78, 552 82, 550 ...  255.0   \n",
       "4  POLYGON ((734 38, 734 40, 732 40, 732 42, 728 ...  255.0   \n",
       "\n",
       "                             polygon_id  \\\n",
       "0  b44cd049-e8f6-4af9-84d6-c1327af8b46d   \n",
       "1  0fa46888-a175-4802-ad94-93425524dc71   \n",
       "2  9807c798-dcc7-4afc-859d-c55c5d5873ef   \n",
       "3  ceb99454-2f1c-48a5-ae5f-d5e64020711e   \n",
       "4  298c5b42-88d1-4b86-bbba-822939099be8   \n",
       "\n",
       "                                   img_id  \n",
       "0  test_localization_00000_prediction.png  \n",
       "1  test_localization_00000_prediction.png  \n",
       "2  test_localization_00000_prediction.png  \n",
       "3  test_localization_00000_prediction.png  \n",
       "4  test_localization_00000_prediction.png  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pd.read_csv(data_dir/\"test_polygons_edt.csv\")\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[\"crop_filename\"] = labels.polygon_id.apply(lambda x: f\"{x}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uuid</th>\n",
       "      <th>img_id_pre</th>\n",
       "      <th>img_id_post</th>\n",
       "      <th>label</th>\n",
       "      <th>crop_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93d0ff06-ab71-45d9-9ace-6f7d86d5d5d8</td>\n",
       "      <td>palu-tsunami_00000024_pre_disaster.png</td>\n",
       "      <td>palu-tsunami_00000024_post_disaster.png</td>\n",
       "      <td>0</td>\n",
       "      <td>93d0ff06-ab71-45d9-9ace-6f7d86d5d5d8.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>437988fc-fb7e-4b0e-8ccf-403015a737b3</td>\n",
       "      <td>palu-tsunami_00000024_pre_disaster.png</td>\n",
       "      <td>palu-tsunami_00000024_post_disaster.png</td>\n",
       "      <td>0</td>\n",
       "      <td>437988fc-fb7e-4b0e-8ccf-403015a737b3.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>63d78637-7c40-40c7-a1b3-55152a64415a</td>\n",
       "      <td>palu-tsunami_00000024_pre_disaster.png</td>\n",
       "      <td>palu-tsunami_00000024_post_disaster.png</td>\n",
       "      <td>0</td>\n",
       "      <td>63d78637-7c40-40c7-a1b3-55152a64415a.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31ccdff0-b7f7-4884-8e55-d35e4d2c1770</td>\n",
       "      <td>palu-tsunami_00000024_pre_disaster.png</td>\n",
       "      <td>palu-tsunami_00000024_post_disaster.png</td>\n",
       "      <td>0</td>\n",
       "      <td>31ccdff0-b7f7-4884-8e55-d35e4d2c1770.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67fdaa2a-3d1f-4c7d-a63b-f08a4a4cb05b</td>\n",
       "      <td>palu-tsunami_00000024_pre_disaster.png</td>\n",
       "      <td>palu-tsunami_00000024_post_disaster.png</td>\n",
       "      <td>0</td>\n",
       "      <td>67fdaa2a-3d1f-4c7d-a63b-f08a4a4cb05b.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   uuid  \\\n",
       "0  93d0ff06-ab71-45d9-9ace-6f7d86d5d5d8   \n",
       "1  437988fc-fb7e-4b0e-8ccf-403015a737b3   \n",
       "2  63d78637-7c40-40c7-a1b3-55152a64415a   \n",
       "3  31ccdff0-b7f7-4884-8e55-d35e4d2c1770   \n",
       "4  67fdaa2a-3d1f-4c7d-a63b-f08a4a4cb05b   \n",
       "\n",
       "                               img_id_pre  \\\n",
       "0  palu-tsunami_00000024_pre_disaster.png   \n",
       "1  palu-tsunami_00000024_pre_disaster.png   \n",
       "2  palu-tsunami_00000024_pre_disaster.png   \n",
       "3  palu-tsunami_00000024_pre_disaster.png   \n",
       "4  palu-tsunami_00000024_pre_disaster.png   \n",
       "\n",
       "                               img_id_post  label  \\\n",
       "0  palu-tsunami_00000024_post_disaster.png      0   \n",
       "1  palu-tsunami_00000024_post_disaster.png      0   \n",
       "2  palu-tsunami_00000024_post_disaster.png      0   \n",
       "3  palu-tsunami_00000024_post_disaster.png      0   \n",
       "4  palu-tsunami_00000024_post_disaster.png      0   \n",
       "\n",
       "                              crop_filename  \n",
       "0  93d0ff06-ab71-45d9-9ace-6f7d86d5d5d8.png  \n",
       "1  437988fc-fb7e-4b0e-8ccf-403015a737b3.png  \n",
       "2  63d78637-7c40-40c7-a1b3-55152a64415a.png  \n",
       "3  31ccdff0-b7f7-4884-8e55-d35e4d2c1770.png  \n",
       "4  67fdaa2a-3d1f-4c7d-a63b-f08a4a4cb05b.png  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "damage_crops_test_folder = data_dir / \"classification_crops_test\"\n",
    "classification_labels = pd.read_csv(data_dir/\"train_pre_post.csv\")\n",
    "classification_labels[\"crop_filename\"] = classification_labels.uuid.apply(lambda x: f\"{x}.png\")\n",
    "classification_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageDataBunch;\n",
       "\n",
       "Train: LabelList (131073 items)\n",
       "x: ImageList\n",
       "Image (3, 64, 64),Image (3, 64, 64),Image (3, 64, 64),Image (3, 64, 64),Image (3, 64, 64)\n",
       "y: CategoryList\n",
       "0,0,0,0,0\n",
       "Path: /media/wwymak/Storage/xView2/classification_crops_post;\n",
       "\n",
       "Valid: LabelList (32768 items)\n",
       "x: ImageList\n",
       "Image (3, 64, 64),Image (3, 64, 64),Image (3, 64, 64),Image (3, 64, 64),Image (3, 64, 64)\n",
       "y: CategoryList\n",
       "0,0,3,0,3\n",
       "Path: /media/wwymak/Storage/xView2/classification_crops_post;\n",
       "\n",
       "Test: LabelList (33614 items)\n",
       "x: ImageList\n",
       "Image (3, 64, 64),Image (3, 64, 64),Image (3, 64, 64),Image (3, 64, 64),Image (3, 64, 64)\n",
       "y: EmptyLabelList\n",
       ",,,,\n",
       "Path: /media/wwymak/Storage/xView2/classification_crops_post"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size=64\n",
    "bs=32\n",
    "src = (ImageList\n",
    "       .from_df(classification_labels, path=classifcation_crop_dir, cols=['crop_filename'])\n",
    "       .filter_by_func(lambda f:Path(f).name )\n",
    "       .split_by_rand_pct(0.2)\n",
    "       .label_from_df(cols='label'))\n",
    "\n",
    "data = (src\n",
    "        .transform(get_transforms(do_flip=True, \n",
    "             flip_vert=True, \n",
    "             max_rotate=180, \n",
    "             max_zoom=1.2, \n",
    "             max_lighting=0.5,\n",
    "             max_warp=0.2, \n",
    "             p_affine=0.75, \n",
    "             p_lighting=0.75), size=size, tfm_y=False)\n",
    "        .add_test_folder(damage_crops_test_folder)\n",
    "        .databunch(bs=bs)\n",
    "        .normalize(imagenet_stats))\n",
    "\n",
    "#test_data = ImageList.from_df(labels, path=damage_crops_test_folder, cols=['crop_filename'])\n",
    "# data.add_test_folder(damage_crops_test_folder)\n",
    "\n",
    "def f1(y_pred:Tensor, y_true:Tensor):\n",
    "    eps=1e-10\n",
    "    def to_onehot(indices, num_classes):\n",
    "        \"\"\"Convert a tensor of indices of any shape `(N, ...)` to a\n",
    "        tensor of one-hot indicators of shape `(N, num_classes, ...) and of type uint8. Output's device is equal to the\n",
    "        input's device`.\n",
    "        \"\"\"\n",
    "        onehot = torch.zeros(indices.shape[0], num_classes, *indices.shape[1:],\n",
    "                             dtype=torch.uint8,\n",
    "                             device=indices.device)\n",
    "        return onehot.scatter_(1, indices.unsqueeze(1), 1)\n",
    "    def recall(y_pred,y_true):\n",
    "        \"\"\"Recall metric.\n",
    "        Only computes a batch-wise average of recall.\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = torch.sum(torch.round(torch.clamp(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = torch.sum(y_true)\n",
    "        recall = true_positives / (possible_positives + eps)\n",
    "        return recall\n",
    "\n",
    "    def precision(y_pred,y_true):\n",
    "        \"\"\"Precision metric.\n",
    "        Only computes a batch-wise average of precision.\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = torch.sum(torch.round(torch.clamp(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = torch.sum(torch.round(torch.clamp(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives +eps)\n",
    "        return precision\n",
    "\n",
    "    y_true = to_onehot(y_true.view(-1), num_classes=4)\n",
    "    precision = precision(y_pred,y_true)\n",
    "    recall = recall(y_pred,y_true)\n",
    "    return 2*((precision*recall)/(precision+recall+eps))\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = data_dir / \"models\"\n",
    "learn = cnn_learner(data,models.resnet50, metrics=[accuracy, f1] , model_dir=models_path)\n",
    "learn.to_fp16();\n",
    "learn.load('15Nov-classification_full_dataset');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = learn.get_preds(DatasetType.Test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.5370, 0.1131, 0.3440, 0.0059],\n",
       "        [0.8794, 0.0708, 0.0411, 0.0087],\n",
       "        [0.9599, 0.0114, 0.0260, 0.0027],\n",
       "        ...,\n",
       "        [0.9340, 0.0183, 0.0430, 0.0048],\n",
       "        [0.7526, 0.1379, 0.0978, 0.0116],\n",
       "        [0.9691, 0.0126, 0.0163, 0.0020]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33970, 5)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33614, 6)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon_ids = [x.name.replace('.png', '') for x in data.test_dl.dataset.items]\n",
    "prediction_cls = [x+1 for x in predictions[1].numpy()]\n",
    "\n",
    "test_results = pd.DataFrame(data={'polygon_id': polygon_ids, 'damage_cls': prediction_cls})\n",
    "test_results = labels.merge(test_results, left_on='polygon_id', right_on='polygon_id')\n",
    "test_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results.geometry = test_results.geometry.apply(lambda x: wkt.loads(x).exterior)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geometry</th>\n",
       "      <th>value</th>\n",
       "      <th>polygon_id</th>\n",
       "      <th>img_id</th>\n",
       "      <th>crop_filename</th>\n",
       "      <th>damage_cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LINEARRING (612 10, 612 12, 608 12, 608 16, 60...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>b44cd049-e8f6-4af9-84d6-c1327af8b46d</td>\n",
       "      <td>test_localization_00000_prediction.png</td>\n",
       "      <td>b44cd049-e8f6-4af9-84d6-c1327af8b46d.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LINEARRING (736 0, 736 2, 738 2, 738 4, 742 4,...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>0fa46888-a175-4802-ad94-93425524dc71</td>\n",
       "      <td>test_localization_00000_prediction.png</td>\n",
       "      <td>0fa46888-a175-4802-ad94-93425524dc71.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LINEARRING (572 44, 572 48, 570 48, 570 50, 56...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>9807c798-dcc7-4afc-859d-c55c5d5873ef</td>\n",
       "      <td>test_localization_00000_prediction.png</td>\n",
       "      <td>9807c798-dcc7-4afc-859d-c55c5d5873ef.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LINEARRING (556 76, 556 78, 552 78, 552 82, 55...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>ceb99454-2f1c-48a5-ae5f-d5e64020711e</td>\n",
       "      <td>test_localization_00000_prediction.png</td>\n",
       "      <td>ceb99454-2f1c-48a5-ae5f-d5e64020711e.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LINEARRING (734 38, 734 40, 732 40, 732 42, 72...</td>\n",
       "      <td>255.0</td>\n",
       "      <td>298c5b42-88d1-4b86-bbba-822939099be8</td>\n",
       "      <td>test_localization_00000_prediction.png</td>\n",
       "      <td>298c5b42-88d1-4b86-bbba-822939099be8.png</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            geometry  value  \\\n",
       "0  LINEARRING (612 10, 612 12, 608 12, 608 16, 60...  255.0   \n",
       "1  LINEARRING (736 0, 736 2, 738 2, 738 4, 742 4,...  255.0   \n",
       "2  LINEARRING (572 44, 572 48, 570 48, 570 50, 56...  255.0   \n",
       "3  LINEARRING (556 76, 556 78, 552 78, 552 82, 55...  255.0   \n",
       "4  LINEARRING (734 38, 734 40, 732 40, 732 42, 72...  255.0   \n",
       "\n",
       "                             polygon_id  \\\n",
       "0  b44cd049-e8f6-4af9-84d6-c1327af8b46d   \n",
       "1  0fa46888-a175-4802-ad94-93425524dc71   \n",
       "2  9807c798-dcc7-4afc-859d-c55c5d5873ef   \n",
       "3  ceb99454-2f1c-48a5-ae5f-d5e64020711e   \n",
       "4  298c5b42-88d1-4b86-bbba-822939099be8   \n",
       "\n",
       "                                   img_id  \\\n",
       "0  test_localization_00000_prediction.png   \n",
       "1  test_localization_00000_prediction.png   \n",
       "2  test_localization_00000_prediction.png   \n",
       "3  test_localization_00000_prediction.png   \n",
       "4  test_localization_00000_prediction.png   \n",
       "\n",
       "                              crop_filename  damage_cls  \n",
       "0  b44cd049-e8f6-4af9-84d6-c1327af8b46d.png           1  \n",
       "1  0fa46888-a175-4802-ad94-93425524dc71.png           1  \n",
       "2  9807c798-dcc7-4afc-859d-c55c5d5873ef.png           1  \n",
       "3  ceb99454-2f1c-48a5-ae5f-d5e64020711e.png           1  \n",
       "4  298c5b42-88d1-4b86-bbba-822939099be8.png           1  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.damage_cls.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions2 = learn.get_preds(DatasetType.Valid)\n",
    "predictions2[1].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.741438\n",
       "1    0.089351\n",
       "2    0.086494\n",
       "3    0.082716\n",
       "dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(predictions2[1].numpy()).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions, y, losses = learn.get_preds(ds_type=DatasetType.Test, with_loss=True)\n",
    "y = torch.argmax(predictions, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33614, 6), array([1, 4, 2, 3]))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polygon_ids = [x.name.replace('.png', '') for x in data.test_dl.dataset.items]\n",
    "prediction_cls = [x+1 for x in y.numpy()]\n",
    "\n",
    "test_results = pd.DataFrame(data={'polygon_id': polygon_ids, 'damage_cls': prediction_cls})\n",
    "test_results = labels.merge(test_results, left_on='polygon_id', right_on='polygon_id')\n",
    "test_results.geometry = test_results.geometry.apply(lambda x: wkt.loads(x).exterior)\n",
    "test_results.img_id = test_results.img_id.str.replace('pre', 'post')\n",
    "test_results.shape, test_results.damage_cls.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.919557\n",
       "4    0.061373\n",
       "3    0.010145\n",
       "2    0.008925\n",
       "Name: damage_cls, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.damage_cls.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"100.0\" height=\"100.0\" viewBox=\"746.4 936.4 43.200000000000045 31.200000000000045\" preserveAspectRatio=\"xMinYMin meet\"><g transform=\"matrix(1,0,0,-1,0,1904.0)\"><polyline fill=\"none\" stroke=\"#66cc99\" stroke-width=\"0.8640000000000009\" points=\"754.0,938.0 754.0,940.0 752.0,940.0 752.0,942.0 750.0,942.0 750.0,956.0 748.0,956.0 748.0,960.0 750.0,960.0 750.0,964.0 752.0,964.0 752.0,966.0 754.0,966.0 754.0,962.0 756.0,962.0 756.0,960.0 768.0,960.0 768.0,962.0 784.0,962.0 784.0,960.0 786.0,960.0 786.0,958.0 788.0,958.0 788.0,946.0 786.0,946.0 786.0,944.0 784.0,944.0 784.0,942.0 770.0,942.0 770.0,940.0 758.0,940.0 758.0,938.0 754.0,938.0\" opacity=\"0.8\" /></g></svg>"
      ],
      "text/plain": [
       "<shapely.geometry.polygon.LinearRing at 0x7f37385f75c0>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.geometry[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cv2 import fillPoly, imwrite\n",
    "def create_image(img_id, output_path):\n",
    "    \n",
    "    mask_img = np.zeros((1024,1024,1), np.uint8)\n",
    "    img_polys = test_results[test_results.img_id == img_id]\n",
    "    if len(img_polys) > 0:\n",
    "        for r in img_polys.iterrows():\n",
    "            row = r[1]\n",
    "            poly_np = np.array(row.geometry.coords, np.int32)\n",
    "            fillPoly(mask_img, [poly_np], row['damage_cls'])\n",
    "\n",
    "    imwrite(str(output_path/img_id), mask_img)\n",
    "    return mask_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/media/wwymak/Storage/xView2/test_masks/test_pre_00909.png'),\n",
       " PosixPath('/media/wwymak/Storage/xView2/test_masks/test_pre_00371.png'),\n",
       " PosixPath('/media/wwymak/Storage/xView2/test_masks/test_pre_00824.png'),\n",
       " PosixPath('/media/wwymak/Storage/xView2/test_masks/test_pre_00270.png'),\n",
       " PosixPath('/media/wwymak/Storage/xView2/test_masks/test_pre_00186.png')]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_dir/\"test_masks\").ls()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test_post_00082.png',\n",
       " 'test_post_00294.png',\n",
       " 'test_post_00839.png',\n",
       " 'test_post_00627.png',\n",
       " 'test_post_00128.png']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path = data_dir/\"test_masks_edt\"\n",
    "img_ids = [x.name for x in (data_dir/\"test\"/\"images\").ls() if 'post' in x.name]\n",
    "len(img_ids)\n",
    "img_ids[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 933/933 [00:03<00:00, 297.68it/s]\n"
     ]
    }
   ],
   "source": [
    "outputs = [create_image(img_id, output_path) for img_id in tqdm(img_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(outputs).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_to_submit(img_path):\n",
    "    img_path.rename(Path(img_path.parent, img_path.name.replace('post', 'damage').replace('pre', 'localization').replace('.png', '_prediction.png')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "_=[rename_to_submit(x) for x in output_path.ls()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/media/wwymak/Storage/xView2/test_masks/test_damage_00732_prediction.png'),\n",
       " PosixPath('/media/wwymak/Storage/xView2/test_masks/test_localization_00923_prediction.png'),\n",
       " PosixPath('/media/wwymak/Storage/xView2/test_masks/test_localization_00265_prediction.png'),\n",
       " PosixPath('/media/wwymak/Storage/xView2/test_masks/test_localization_00058_prediction.png'),\n",
       " PosixPath('/media/wwymak/Storage/xView2/test_masks/test_damage_00099_prediction.png')]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_path.ls()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai-solaris",
   "language": "python",
   "name": "fastai-solaris"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
